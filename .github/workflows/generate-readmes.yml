name: Generate Sub-READMEs

on:
  workflow_dispatch: # å…è®¸æ‰‹åŠ¨è§¦å‘
  workflow_run:      # å½“æ›´æ–°æ–‡ä»¶çš„é‚£ä¸ªå·¥ä½œæµå®Œæˆåè‡ªåŠ¨è¿è¡Œ
    workflows: ["Update File Test"]
    types:
      - completed

permissions:
  contents: write

jobs:
  generate-readmes:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    steps:
      - name: æ£€æŸ¥ä»£ç ä»“åº“
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}

      - name: è®¾ç½® Python ç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: å®‰è£…ä¾èµ–
        run: pip install pyyaml

      - name: è¿è¡Œæ™ºèƒ½å¯¹æ¯”ç”Ÿæˆè„šæœ¬
        run: |
          python3 -c '
          import os
          import urllib.parse
          import yaml
          import datetime

          # --- é…ç½®åŒºåŸŸ ---
          REPO_URL = "https://github.com/${{ github.repository }}/blob/main"
          
          # æ–‡ä»¶å¤¹æ˜¾ç¤ºåç§°æ˜ å°„
          DIR_MAP = {
              "Official_Examples": "Mihomo å®˜æ–¹ç¤ºä¾‹ (Official)",
              "General_Config": "é€šç”¨è¿›é˜¶é…ç½® (General Config)",
              "Smart_Mode": "Smart æ¨¡å¼ / è·¯ç”±ä¸“ç”¨ (Smart Mode)",
              "Mobile_Modules": "Android æ‰‹æœºæ¨¡å— (Mobile Modules)"
          }

          # å¿½ç•¥çš„æ–‡ä»¶
          IGNORE_DIRS = [".git", ".github"]
          IGNORE_FILES = ["README.md", "LICENSE", "release_body.md"]

          # --- è¾…åŠ©å‡½æ•° ---

          def safe_get(data, keys, default="N/A"):
              val = data
              try:
                  for key in keys:
                      val = val[key]
                  return val
              except:
                  return default

          def get_file_size(path):
              try:
                  size = os.path.getsize(path)
                  if size < 1024: return f"{size} B"
                  return f"{size/1024:.1f} KB"
              except: return "Unknown"

          def analyze_single_config(file_path):
              """è§£æå•ä¸ª YAML å¹¶è¿”å›ç»“æ„åŒ–æ•°æ®"""
              try:
                  with open(file_path, "r", encoding="utf-8") as f:
                      data = yaml.safe_load(f)
                      
                  # åŸºç¡€æŒ‡æ ‡æå–
                  info = {}
                  info["mixed_port"] = safe_get(data, ["mixed-port"], "âŒ")
                  info["http_port"] = safe_get(data, ["port"], "âŒ")
                  info["mode"] = safe_get(data, ["mode"], "Rule")
                  info["ipv6"] = "âœ…" if str(safe_get(data, ["ipv6"])).lower() == "true" else "ğŸš«"
                  info["allow_lan"] = "âœ…" if str(safe_get(data, ["allow-lan"])).lower() == "true" else "ğŸš«"
                  
                  # è¿›é˜¶æŒ‡æ ‡
                  info["tun"] = "âœ… å¼€å¯" if safe_get(data, ["tun", "enable"], False) else "ğŸš« å…³é—­"
                  
                  # æ•°é‡ç»Ÿè®¡
                  groups = data.get("proxy-groups", [])
                  info["group_count"] = len(groups) if groups else 0
                  
                  rules = data.get("rules", [])
                  info["rule_count"] = len(rules) if rules else 0
                  
                  # ç­–ç•¥ç»„è¯¦æƒ… (ç”¨äºç”Ÿæˆè¯¦ç»†æŠ¥å‘Š)
                  info["groups_raw"] = []
                  for pg in groups:
                      name = pg.get("name", "Unknown")
                      type_ = pg.get("type", "select")
                      icon = "ğŸš€"
                      if "auto" in type_ or "url-test" in type_: icon = "â™»ï¸"
                      elif "fallback" in type_: icon = "ğŸ”§"
                      elif "load-balance" in type_: icon = "âš–ï¸"
                      elif "select" in type_: icon = "ğŸ‘†"
                      info["groups_raw"].append(f"| {icon} {name} | `{type_}` |")

                  # DNS è¯¦æƒ…
                  info["dns_raw"] = []
                  dns = data.get("dns", {})
                  if dns.get("enable", False):
                      for ns in dns.get("nameserver", []):
                          if isinstance(ns, str):
                              provider = "DoT" if "tls://" in ns else "DoH" if "https://" in ns else "UDP"
                              info["dns_raw"].append(f"| {provider} | `{ns}` |")
                  
                  return info
              except Exception as e:
                  # print(f"Parse error {file_path}: {e}")
                  return None

          def generate_comparison_table(configs_data):
              """ç”Ÿæˆæ¨ªå‘å¯¹æ¯”è¡¨æ ¼"""
              # è¡¨å¤´
              headers = ["ç‰¹æ€§ / æ–‡ä»¶", "å¤§å° (Size)"] 
              for filename in configs_data.keys():
                  headers.append(f"`{filename}`")
              
              lines = []
              lines.append("| " + " | ".join(headers) + " |")
              lines.append("| :--- | :--- " + "| :--- " * len(configs_data) + "|")
              
              # å®šä¹‰è¦å¯¹æ¯”çš„è¡Œ
              rows = [
                  ("mixed_port", "æ··åˆç«¯å£"),
                  ("mode", "è¿è¡Œæ¨¡å¼"),
                  ("tun", "TUN æ¨¡å¼"),
                  ("ipv6", "IPv6"),
                  ("allow_lan", "å…è®¸å±€åŸŸç½‘"),
                  ("group_count", "ç­–ç•¥ç»„æ•°é‡"),
                  ("rule_count", "è§„åˆ™æ¡æ•°"),
              ]

              # å¡«å……ç¬¬ä¸€è¡Œï¼šæ–‡ä»¶å¤§å°
              size_row = ["**æ–‡ä»¶å¤§å°**", "-"]
              for filename, data in configs_data.items():
                  size_row.append(data["file_size"])
              lines.append("| " + " | ".join(size_row) + " |")

              # å¡«å……å…¶ä»–ç‰¹æ€§è¡Œ
              for key, label in rows:
                  row_content = [f"**{label}**", "-"]
                  for filename, data in configs_data.items():
                      val = data.get("parsed", {}).get(key, "N/A")
                      # ç¾åŒ–æ•°å­—æ˜¾ç¤º
                      if key in ["group_count", "rule_count"]:
                          val = f"**{val}**"
                      row_content.append(str(val))
                  lines.append("| " + " | ".join(row_content) + " |")
              
              return "\n".join(lines)

          def generate_readme(root_path, files):
              rel_path = os.path.relpath(root_path, ".")
              folder_name = os.path.basename(root_path)
              title = DIR_MAP.get(folder_name, folder_name)

              # 1. æ‰«æå¹¶è§£ææ‰€æœ‰ YAML
              configs_data = {} # {filename: {file_size, parsed}}
              valid_yaml_files = []
              
              for f in sorted(files):
                  if f.lower().endswith((".yaml", ".yml")) and f not in IGNORE_FILES:
                      full_path = os.path.join(root_path, f)
                      # å°è¯•è§£æ
                      parsed_info = analyze_single_config(full_path)
                      
                      # åªæœ‰åŒ…å« proxy-groups æˆ– rules çš„æ‰è¢«è®¤ä¸ºæ˜¯å®Œæ•´é…ç½®ï¼Œå‚ä¸å¯¹æ¯”
                      if parsed_info and (parsed_info["group_count"] > 0 or parsed_info["rule_count"] > 0):
                          configs_data[f] = {
                              "file_size": get_file_size(full_path),
                              "parsed": parsed_info
                          }
                          valid_yaml_files.append(f)

              # --- å¼€å§‹æ„å»º Markdown ---
              content = []
              content.append(f"# ğŸ“‚ {title}\n")
              
              # å¯¼èˆªæ 
              depth = rel_path.count(os.sep) + 1
              back_link = "../" * depth + "README.md"
              content.append(f"[ğŸ”™ è¿”å›ä¸»é¡µ (Return to Home)]({back_link})\n")

              content.append("> ğŸ¤– **è‡ªåŠ¨åˆ†ææŠ¥å‘Š** | Auto-generated Report\n")
              content.append(f"> æœ¬ç›®å½•åŒ…å« **{len(valid_yaml_files)}** ä¸ªä¸»è¦é…ç½®æ–‡ä»¶ã€‚\n")

              # --- æ¨¡å— 1: å¯¹æ¯”è¡¨æ ¼ (å¦‚æœæœ‰å¤šä¸ªé…ç½®) ---
              if len(configs_data) > 1:
                  content.append("## âš”ï¸ é…ç½®æ¨ªå‘å¯¹æ¯” (Comparison)\n")
                  content.append(generate_comparison_table(configs_data))
                  content.append("\n")
              
              # --- æ¨¡å— 2: è¯¦ç»†åˆ†æ (é’ˆå¯¹æ¯ä¸ªæ–‡ä»¶) ---
              if configs_data:
                  content.append("## ğŸ“„ é…ç½®æ–‡ä»¶è¯¦è§£ (Details)\n")
                  for filename, data in configs_data.items():
                      info = data["parsed"]
                      file_url = f"{REPO_URL}/{urllib.parse.quote(rel_path)}/{urllib.parse.quote(filename)}"
                      
                      content.append(f"### ğŸ“ {filename}")
                      content.append(f"- **å¤§å°**: {data['file_size']}")
                      content.append(f"- **é“¾æ¥**: [æŸ¥çœ‹æºç ]({file_url})")
                      
                      # ç­–ç•¥ç»„é¢„è§ˆ
                      if info["groups_raw"]:
                          content.append(f"\n<details>")
                          content.append(f"<summary><b>ğŸ” ç‚¹å‡»æŸ¥çœ‹ç­–ç•¥ç»„æ¶æ„ ({info['group_count']}ä¸ª)</b></summary>\n")
                          content.append("| ç­–ç•¥ç»„ (Group) | ç±»å‹ (Type) |")
                          content.append("| :--- | :--- |")
                          content.extend(info["groups_raw"][:15]) # é™åˆ¶é•¿åº¦
                          if len(info["groups_raw"]) > 15:
                              content.append(f"| ... | è¿˜æœ‰ {len(info['groups_raw'])-15} ä¸ª |")
                          content.append(f"\n</details>\n")
                      
                      # DNS é¢„è§ˆ
                      if info["dns_raw"]:
                          content.append(f"\n<details>")
                          content.append(f"<summary><b>ğŸŒ ç‚¹å‡»æŸ¥çœ‹ DNS é…ç½®</b></summary>\n")
                          content.append("| ç±»å‹ | æœåŠ¡å™¨ |")
                          content.append("| :--- | :--- |")
                          content.extend(info["dns_raw"])
                          content.append(f"\n</details>\n")
                      
                      content.append("\n---\n")

              # --- æ¨¡å— 3: æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ (å…œåº•) ---
              content.append("## ğŸ“¦ æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ (File List)\n")
              content.append("| æ–‡ä»¶å | å¤§å° | é“¾æ¥ |")
              content.append("| :--- | :--- | :--- |")
              for f in sorted(files):
                  if f in IGNORE_FILES or f.startswith("."): continue
                  f_path = os.path.join(root_path, f)
                  f_url = f"{REPO_URL}/{urllib.parse.quote(rel_path)}/{urllib.parse.quote(f)}"
                  content.append(f"| `{f}` | {get_file_size(f_path)} | [æŸ¥çœ‹]({f_url}) |")

              return "\n".join(content)

          # --- ä¸»æ‰§è¡Œé€»è¾‘ ---
          print("Starting Comparison README generation...")
          for root, dirs, files in os.walk("."):
              dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
              
              rel_path = os.path.relpath(root, ".")
              if rel_path == ".": continue

              # åªæœ‰å½“ç›®å½•ä¸‹æœ‰æ–‡ä»¶æ—¶æ‰ç”Ÿæˆ
              if len([f for f in files if f not in IGNORE_FILES]) > 0:
                  readme_txt = generate_readme(root, files)
                  with open(os.path.join(root, "README.md"), "w", encoding="utf-8") as f:
                      f.write(readme_txt)
                  print(f"Generated for: {rel_path}")
          '

      - name: æäº¤æ›´æ”¹
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          git add */**/README.md
          git commit -m "Docs: Auto-generate config comparison tables" || echo "No changes to commit"
          
          git push origin HEAD:${{ github.ref_name }}
name: Generate Sub-READMEs

on:
  workflow_dispatch: # å…è®¸æ‰‹åŠ¨è§¦å‘
  workflow_run:      # å½“æ›´æ–°æ–‡ä»¶çš„é‚£ä¸ªå·¥ä½œæµå®Œæˆåè‡ªåŠ¨è¿è¡Œ
    workflows: ["Update File Test"]
    types:
      - completed

permissions:
  contents: write

jobs:
  generate-readmes:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    steps:
      - name: æ£€æŸ¥ä»£ç ä»“åº“
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}

      - name: è®¾ç½® Python ç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: å®‰è£…ä¾èµ–
        run: pip install pyyaml

      - name: è¿è¡Œæ™ºèƒ½å¯¹æ¯”ç”Ÿæˆè„šæœ¬
        run: |
          python3 -c '
          import os
          import urllib.parse
          import yaml
          import datetime

          # --- é…ç½®åŒºåŸŸ ---
          REPO_URL = "https://github.com/${{ github.repository }}/blob/main"
          
          # æ–‡ä»¶å¤¹æ˜¾ç¤ºåç§°æ˜ å°„
          DIR_MAP = {
              "Official_Examples": "Mihomo å®˜æ–¹ç¤ºä¾‹ (Official)",
              "General_Config": "é€šç”¨è¿›é˜¶é…ç½® (General Config)",
              "Smart_Mode": "Smart æ¨¡å¼ / è·¯ç”±ä¸“ç”¨ (Smart Mode)",
              "Mobile_Modules": "Android æ‰‹æœºæ¨¡å— (Mobile Modules)"
          }

          # å¿½ç•¥çš„æ–‡ä»¶
          IGNORE_DIRS = [".git", ".github"]
          IGNORE_FILES = ["README.md", "LICENSE", "release_body.md"]

          # --- è¾…åŠ©å‡½æ•° ---

          def safe_get(data, keys, default="N/A"):
              val = data
              try:
                  for key in keys:
                      val = val[key]
                  return val
              except:
                  return default

          def get_file_size(path):
              try:
                  size = os.path.getsize(path)
                  if size < 1024: return f"{size} B"
                  return f"{size/1024:.1f} KB"
              except: return "Unknown"

          def analyze_single_config(file_path):
              """è§£æå•ä¸ª YAML å¹¶è¿”å›ç»“æ„åŒ–æ•°æ®"""
              try:
                  with open(file_path, "r", encoding="utf-8") as f:
                      data = yaml.safe_load(f)
                      
                  # åŸºç¡€æŒ‡æ ‡æå–
                  info = {}
                  info["mixed_port"] = safe_get(data, ["mixed-port"], "âŒ")
                  info["http_port"] = safe_get(data, ["port"], "âŒ")
                  info["mode"] = safe_get(data, ["mode"], "Rule")
                  info["ipv6"] = "âœ…" if str(safe_get(data, ["ipv6"])).lower() == "true" else "ğŸš«"
                  info["allow_lan"] = "âœ…" if str(safe_get(data, ["allow-lan"])).lower() == "true" else "ğŸš«"
                  
                  # è¿›é˜¶æŒ‡æ ‡
                  info["tun"] = "âœ… å¼€å¯" if safe_get(data, ["tun", "enable"], False) else "ğŸš« å…³é—­"
                  
                  # æ•°é‡ç»Ÿè®¡
                  groups = data.get("proxy-groups", [])
                  info["group_count"] = len(groups) if groups else 0
                  
                  rules = data.get("rules", [])
                  info["rule_count"] = len(rules) if rules else 0
                  
                  # ç­–ç•¥ç»„è¯¦æƒ… (ç”¨äºç”Ÿæˆè¯¦ç»†æŠ¥å‘Š)
                  info["groups_raw"] = []
                  for pg in groups:
                      name = pg.get("name", "Unknown")
                      type_ = pg.get("type", "select")
                      icon = "ğŸš€"
                      if "auto" in type_ or "url-test" in type_: icon = "â™»ï¸"
                      elif "fallback" in type_: icon = "ğŸ”§"
                      elif "load-balance" in type_: icon = "âš–ï¸"
                      elif "select" in type_: icon = "ğŸ‘†"
                      info["groups_raw"].append(f"| {icon} {name} | `{type_}` |")

                  # DNS è¯¦æƒ…
                  info["dns_raw"] = []
                  dns = data.get("dns", {})
                  if dns.get("enable", False):
                      for ns in dns.get("nameserver", []):
                          if isinstance(ns, str):
                              provider = "DoT" if "tls://" in ns else "DoH" if "https://" in ns else "UDP"
                              info["dns_raw"].append(f"| {provider} | `{ns}` |")
                  
                  return info
              except Exception as e:
                  # print(f"Parse error {file_path}: {e}")
                  return None

          def generate_comparison_table(configs_data):
              """ç”Ÿæˆæ¨ªå‘å¯¹æ¯”è¡¨æ ¼"""
              # è¡¨å¤´
              headers = ["ç‰¹æ€§ / æ–‡ä»¶", "å¤§å° (Size)"] 
              for filename in configs_data.keys():
                  headers.append(f"`{filename}`")
              
              lines = []
              lines.append("| " + " | ".join(headers) + " |")
              lines.append("| :--- | :--- " + "| :--- " * len(configs_data) + "|")
              
              # å®šä¹‰è¦å¯¹æ¯”çš„è¡Œ
              rows = [
                  ("mixed_port", "æ··åˆç«¯å£"),
                  ("mode", "è¿è¡Œæ¨¡å¼"),
                  ("tun", "TUN æ¨¡å¼"),
                  ("ipv6", "IPv6"),
                  ("allow_lan", "å…è®¸å±€åŸŸç½‘"),
                  ("group_count", "ç­–ç•¥ç»„æ•°é‡"),
                  ("rule_count", "è§„åˆ™æ¡æ•°"),
              ]

              # å¡«å……ç¬¬ä¸€è¡Œï¼šæ–‡ä»¶å¤§å°
              size_row = ["**æ–‡ä»¶å¤§å°**", "-"]
              for filename, data in configs_data.items():
                  size_row.append(data["file_size"])
              lines.append("| " + " | ".join(size_row) + " |")

              # å¡«å……å…¶ä»–ç‰¹æ€§è¡Œ
              for key, label in rows:
                  row_content = [f"**{label}**", "-"]
                  for filename, data in configs_data.items():
                      val = data.get("parsed", {}).get(key, "N/A")
                      # ç¾åŒ–æ•°å­—æ˜¾ç¤º
                      if key in ["group_count", "rule_count"]:
                          val = f"**{val}**"
                      row_content.append(str(val))
                  lines.append("| " + " | ".join(row_content) + " |")
              
              return "\n".join(lines)

          def generate_readme(root_path, files):
              rel_path = os.path.relpath(root_path, ".")
              folder_name = os.path.basename(root_path)
              title = DIR_MAP.get(folder_name, folder_name)

              # 1. æ‰«æå¹¶è§£ææ‰€æœ‰ YAML
              configs_data = {} # {filename: {file_size, parsed}}
              valid_yaml_files = []
              
              for f in sorted(files):
                  if f.lower().endswith((".yaml", ".yml")) and f not in IGNORE_FILES:
                      full_path = os.path.join(root_path, f)
                      # å°è¯•è§£æ
                      parsed_info = analyze_single_config(full_path)
                      
                      # åªæœ‰åŒ…å« proxy-groups æˆ– rules çš„æ‰è¢«è®¤ä¸ºæ˜¯å®Œæ•´é…ç½®ï¼Œå‚ä¸å¯¹æ¯”
                      if parsed_info and (parsed_info["group_count"] > 0 or parsed_info["rule_count"] > 0):
                          configs_data[f] = {
                              "file_size": get_file_size(full_path),
                              "parsed": parsed_info
                          }
                          valid_yaml_files.append(f)

              # --- å¼€å§‹æ„å»º Markdown ---
              content = []
              content.append(f"# ğŸ“‚ {title}\n")
              
              # å¯¼èˆªæ 
              depth = rel_path.count(os.sep) + 1
              back_link = "../" * depth + "README.md"
              content.append(f"[ğŸ”™ è¿”å›ä¸»é¡µ (Return to Home)]({back_link})\n")

              content.append("> ğŸ¤– **è‡ªåŠ¨åˆ†ææŠ¥å‘Š** | Auto-generated Report\n")
              content.append(f"> æœ¬ç›®å½•åŒ…å« **{len(valid_yaml_files)}** ä¸ªä¸»è¦é…ç½®æ–‡ä»¶ã€‚\n")

              # --- æ¨¡å— 1: å¯¹æ¯”è¡¨æ ¼ (å¦‚æœæœ‰å¤šä¸ªé…ç½®) ---
              if len(configs_data) > 1:
                  content.append("## âš”ï¸ é…ç½®æ¨ªå‘å¯¹æ¯” (Comparison)\n")
                  content.append(generate_comparison_table(configs_data))
                  content.append("\n")
              
              # --- æ¨¡å— 2: è¯¦ç»†åˆ†æ (é’ˆå¯¹æ¯ä¸ªæ–‡ä»¶) ---
              if configs_data:
                  content.append("## ğŸ“„ é…ç½®æ–‡ä»¶è¯¦è§£ (Details)\n")
                  for filename, data in configs_data.items():
                      info = data["parsed"]
                      file_url = f"{REPO_URL}/{urllib.parse.quote(rel_path)}/{urllib.parse.quote(filename)}"
                      
                      content.append(f"### ğŸ“ {filename}")
                      content.append(f"- **å¤§å°**: {data['file_size']}")
                      content.append(f"- **é“¾æ¥**: [æŸ¥çœ‹æºç ]({file_url})")
                      
                      # ç­–ç•¥ç»„é¢„è§ˆ
                      if info["groups_raw"]:
                          content.append(f"\n<details>")
                          content.append(f"<summary><b>ğŸ” ç‚¹å‡»æŸ¥çœ‹ç­–ç•¥ç»„æ¶æ„ ({info['group_count']}ä¸ª)</b></summary>\n")
                          content.append("| ç­–ç•¥ç»„ (Group) | ç±»å‹ (Type) |")
                          content.append("| :--- | :--- |")
                          content.extend(info["groups_raw"][:15]) # é™åˆ¶é•¿åº¦
                          if len(info["groups_raw"]) > 15:
                              content.append(f"| ... | è¿˜æœ‰ {len(info['groups_raw'])-15} ä¸ª |")
                          content.append(f"\n</details>\n")
                      
                      # DNS é¢„è§ˆ
                      if info["dns_raw"]:
                          content.append(f"\n<details>")
                          content.append(f"<summary><b>ğŸŒ ç‚¹å‡»æŸ¥çœ‹ DNS é…ç½®</b></summary>\n")
                          content.append("| ç±»å‹ | æœåŠ¡å™¨ |")
                          content.append("| :--- | :--- |")
                          content.extend(info["dns_raw"])
                          content.append(f"\n</details>\n")
                      
                      content.append("\n---\n")

              # --- æ¨¡å— 3: æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ (å…œåº•) ---
              content.append("## ğŸ“¦ æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ (File List)\n")
              content.append("| æ–‡ä»¶å | å¤§å° | é“¾æ¥ |")
              content.append("| :--- | :--- | :--- |")
              for f in sorted(files):
                  if f in IGNORE_FILES or f.startswith("."): continue
                  f_path = os.path.join(root_path, f)
                  f_url = f"{REPO_URL}/{urllib.parse.quote(rel_path)}/{urllib.parse.quote(f)}"
                  content.append(f"| `{f}` | {get_file_size(f_path)} | [æŸ¥çœ‹]({f_url}) |")

              return "\n".join(content)

          # --- ä¸»æ‰§è¡Œé€»è¾‘ ---
          print("Starting Comparison README generation...")
          for root, dirs, files in os.walk("."):
              dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
              
              rel_path = os.path.relpath(root, ".")
              if rel_path == ".": continue

              # åªæœ‰å½“ç›®å½•ä¸‹æœ‰æ–‡ä»¶æ—¶æ‰ç”Ÿæˆ
              if len([f for f in files if f not in IGNORE_FILES]) > 0:
                  readme_txt = generate_readme(root, files)
                  with open(os.path.join(root, "README.md"), "w", encoding="utf-8") as f:
                      f.write(readme_txt)
                  print(f"Generated for: {rel_path}")
          '

      - name: æäº¤æ›´æ”¹
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          git add */**/README.md
          git commit -m "Docs: Auto-generate config comparison tables" || echo "No changes to commit"
          
          git push origin HEAD:${{ github.ref_name }}
