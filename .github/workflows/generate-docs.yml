Name: Generate Documentation

on:
  workflow_run:
    workflows: ["Update Configs"]
    types:
      - completed
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-docs:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          ref: ${{ github.ref }}
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install pyyaml

      - name: Generate Category READMEs (Fix Tables)
        run: |
          python3 << 'SCRIPT'
          import os
          import urllib.parse
          import yaml
          
          # é˜²æ­¢ yaml è§£ææœªçŸ¥ tag æŠ¥é”™
          yaml.add_multi_constructor("!", lambda loader, suffix, node: None, Loader=yaml.SafeLoader)

          REPO_URL = "https://github.com/${{ github.repository }}/blob/main"
          # å®šä¹‰åˆ†ç±»ç›®å½•ä¸æ ‡é¢˜
          CATEGORIES = {
              "THEYAMLS/Official_Examples": "Mihomo å®˜æ–¹ç¤ºä¾‹ (Official)",
              "THEYAMLS/General_Config": "é€šç”¨è¿›é˜¶é…ç½® (General Config)",
              "THEYAMLS/Smart_Mode": "Smart æ¨¡å¼ / è·¯ç”±ä¸“ç”¨ (Smart Mode)",
              "THEYAMLS/Mobile_Modules": "Android æ‰‹æœºæ¨¡å— (Mobile Modules)"
          }
          IGNORE_FILES = ["README.md", "LICENSE", "release_body.md"]

          def safe_get(data, keys, default="N/A"):
              val = data
              try:
                  for key in keys:
                      val = val[key]
                  return val
              except:
                  return default

          def get_file_size(path):
              try:
                  size = os.path.getsize(path)
                  if size < 1024: return f"{size} B"
                  return f"{size/1024:.1f} KB"
              except: return "Unknown"

          def escape_md(text):
              """è½¬ä¹‰ Markdown è¡¨æ ¼ä¸­çš„å…³é”®å­—ç¬¦"""
              if not isinstance(text, str): return str(text)
              return text.replace("|", "\\|").replace("\n", " ")

          def read_file_content(file_path):
              content = ""
              try:
                  with open(file_path, "r", encoding="utf-8") as f:
                      content = f.read()
              except UnicodeDecodeError:
                  try:
                      with open(file_path, "r", encoding="gb18030", errors="ignore") as f:
                          content = f.read()
                  except Exception:
                      return None
              if "\t" in content:
                  content = content.replace("\t", "  ")
              return content

          def analyze_single_config(file_path):
              try:
                  raw_content = read_file_content(file_path)
                  if not raw_content: return None
                  data = yaml.safe_load(raw_content)
                  if not isinstance(data, dict): return None

                  info = {}
                  info["mode"] = safe_get(data, ["mode"], "Rule")
                  info["ipv6"] = "âœ…" if str(safe_get(data, ["ipv6"])).lower() == "true" else "ğŸš«"
                  info["allow_lan"] = "âœ…" if str(safe_get(data, ["allow-lan"])).lower() == "true" else "ğŸš«"
                  info["tun"] = "âœ… å¼€å¯" if safe_get(data, ["tun", "enable"], False) else "ğŸš« å…³é—­"
                  info["port_mixed"] = safe_get(data, ["mixed-port"], "-")
                  info["port_ctrl"] = safe_get(data, ["external-controller"], "-")
                  
                  # ç«¯å£æ˜¾ç¤ºä¼˜åŒ–
                  ports_list = []
                  p_mix = data.get("mixed-port")
                  if p_mix: ports_list.append(f"| Mixed (æ··åˆ) | {p_mix} | HTTP/SOCKS |")
                  p_http = data.get("port")
                  if p_http: ports_list.append(f"| HTTP | {p_http} | ä»… HTTP |")
                  p_socks = data.get("socks-port")
                  if p_socks: ports_list.append(f"| SOCKS5 | {p_socks} | ä»… SOCKS |")
                  p_tproxy = data.get("tproxy-port")
                  if p_tproxy: ports_list.append(f"| TProxy | {p_tproxy} | é€æ˜ä»£ç† (UDP) |")
                  p_redir = data.get("redir-port")
                  if p_redir: ports_list.append(f"| Redirect | {p_redir} | é€æ˜ä»£ç† (TCP) |")
                  p_ctrl = data.get("external-controller")
                  if p_ctrl: ports_list.append(f"| Controller | {p_ctrl} | æ§åˆ¶é¢æ¿ |")

                  listeners = data.get("listeners", [])
                  if listeners and isinstance(listeners, list):
                      for l in listeners:
                          if isinstance(l, dict):
                              name = l.get("name", "Unknown")
                              port = l.get("port", "?")
                              l_type = l.get("type", "mixed")
                              ports_list.append(f"| ğŸ‘‚ {name} | {port} | {l_type} |")
                  
                  info["ports_display_lines"] = ports_list
                  
                  # ç»Ÿè®¡æ•°é‡
                  groups = data.get("proxy-groups", [])
                  info["group_count"] = len(groups) if isinstance(groups, list) else 0
                  rules = data.get("rules", [])
                  info["rule_count"] = len(rules) if isinstance(rules, list) else 0
                  
                  # ç­–ç•¥ç»„æ¦‚è§ˆ
                  info["groups_raw"] = []
                  if isinstance(groups, list):
                      for pg in groups:
                          if isinstance(pg, dict):
                              name = escape_md(pg.get("name", "Unknown"))
                              type_ = pg.get("type", "select")
                              icon = "ğŸš€"
                              if "auto" in type_ or "url-test" in type_: icon = "â™»ï¸"
                              elif "fallback" in type_: icon = "ğŸ”§"
                              elif "load-balance" in type_: icon = "âš–ï¸"
                              elif "select" in type_: icon = "ğŸ‘†"
                              info["groups_raw"].append(f"| {icon} {name} | `{type_}` |")

                  # DNS æ¦‚è§ˆ
                  info["dns_raw"] = []
                  dns = data.get("dns", {})
                  if isinstance(dns, dict) and dns.get("enable", False):
                      nameservers = dns.get("nameserver", [])
                      if isinstance(nameservers, list):
                          for ns in nameservers:
                              if isinstance(ns, str):
                                  provider = "DoT" if "tls://" in ns else "DoH" if "https://" in ns else "UDP"
                                  info["dns_raw"].append(f"| {provider} | `{escape_md(ns)}` |")
                  
                  return info
              except Exception as e:
                  return None

          def generate_category_readme(folder_path, title):
              if not os.path.exists(folder_path): return None
              rel_folder = os.path.relpath(folder_path, ".")
              
              all_files = []
              for root, dirs, files in os.walk(folder_path):
                  dirs[:] = [d for d in dirs if not d.startswith('.')]
                  for f in files:
                      if f.endswith(('.yaml', '.yml')) and f not in IGNORE_FILES:
                          full_path = os.path.join(root, f)
                          rel_path = os.path.relpath(full_path, folder_path)
                          all_files.append((rel_path, full_path))
              
              if not all_files: return None

              configs_data = {}
              for rel_path, full_path in all_files:
                  parsed = analyze_single_config(full_path)
                  if parsed:
                      configs_data[rel_path] = {
                          "file_size": get_file_size(full_path),
                          "parsed": parsed,
                          "full_path": full_path
                      }

              if not configs_data: return None

              lines = []
              lines.append(f"# ğŸ“‚ {title}")
              lines.append("")
              lines.append(f"[ğŸ”™ è¿”å›ä¸»é¡µ](../../README.md)") # ä¿®æ­£è¿”å›ä¸»é¡µçš„ç›¸å¯¹è·¯å¾„
              lines.append("")
              lines.append("> ğŸ¤– **è‡ªåŠ¨æŠ€æœ¯åˆ†ææŠ¥å‘Š** | Auto-generated Technical Report")
              lines.append("")

              # --- æ¨ªå‘å¯¹æ¯”è¡¨æ ¼ç”Ÿæˆ (ä¿®å¤å¯¹é½é—®é¢˜) ---
              if len(configs_data) > 1:
                  lines.append("## âš”ï¸ é…ç½®æ¨ªå‘å¯¹æ¯” (Comparison)")
                  lines.append("")
                  
                  display_items = list(configs_data.items())[:10] # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªé˜²æ­¢è¡¨æ ¼è¿‡å®½
                  headers = ["ç‰¹æ€§ / æ–‡ä»¶"] + [f"`{os.path.basename(p)}`" for p, _ in display_items]
                  
                  # 1. Header
                  lines.append("| " + " | ".join(headers) + " |")
                  # 2. Separator (å…³é”®ï¼šå¿…é¡»ä¸Headeråˆ—æ•°ä¸€è‡´)
                  lines.append("| :--- " + "| :--- " * len(display_items) + "|")
                  
                  # 3. Size Row
                  size_row = ["**å¤§å°**"] + [d.get("file_size", "N/A") for _, d in display_items]
                  lines.append("| " + " | ".join(size_row) + " |")
                  
                  # 4. Data Rows
                  rows = [
                      ("port_mixed", "æ··åˆç«¯å£"), ("port_ctrl", "é¢æ¿ç«¯å£"),
                      ("mode", "è¿è¡Œæ¨¡å¼"), ("tun", "TUN æ¨¡å¼"),
                      ("group_count", "ç­–ç•¥ç»„æ•°"), ("rule_count", "è§„åˆ™æ¡æ•°"),
                  ]
                  for key, label in rows:
                      row_content = [f"**{label}**"]
                      for _, data in display_items:
                          val = data.get("parsed", {}).get(key, "N/A")
                          if key in ["group_count", "rule_count"]: val = f"**{val}**"
                          row_content.append(str(val))
                      lines.append("| " + " | ".join(row_content) + " |")
                  lines.append("")

              # --- è¯¦ç»†å†…å®¹ ---
              lines.append("## ğŸ“„ é…ç½®æ–‡ä»¶è¯¦è§£ (Details by Author)")
              lines.append("")
              
              by_author = {}
              for rel_path, data in configs_data.items():
                  # å‡è®¾ä¸€çº§ç›®å½•åä¸ºä½œè€…å
                  author = rel_path.split(os.sep)[0] if os.sep in rel_path else "Unknown"
                  if author not in by_author: by_author[author] = []
                  by_author[author].append((rel_path, data))
              
              for author, items in sorted(by_author.items()):
                  lines.append(f"### ğŸ‘¤ {author}")
                  lines.append("")
                  
                  for rel_path, data in items:
                      filename = os.path.basename(rel_path)
                      info = data["parsed"]
                      # æ„å»º Raw é“¾æ¥
                      file_url = f"{REPO_URL}/{rel_folder}/{urllib.parse.quote(rel_path.replace(os.sep, '/'))}"
                      
                      lines.append(f"#### ğŸ“ {filename}")
                      lines.append(f"- **è·¯å¾„**: `{rel_path}` | **å¤§å°**: {data['file_size']} | **[Raw]({file_url})**")
                      
                      port_lines = info.get("ports_display_lines", [])
                      if port_lines:
                          lines.append("")
                          lines.append("**ç«¯å£é…ç½®**:")
                          lines.append("")
                          lines.append("| ç±»å‹ | ç«¯å£ | è¯´æ˜ |")
                          lines.append("| :--- | :--- | :--- |")
                          lines.extend(port_lines)
                          lines.append("")
                      
                      groups_raw = info.get("groups_raw", [])
                      if groups_raw:
                          lines.append(f"<details>")
                          lines.append(f"<summary>ğŸ” ç­–ç•¥ç»„æ¶æ„ ({len(groups_raw)}ä¸ª) - ç‚¹å‡»å±•å¼€</summary>")
                          lines.append("") # å¿…é¡»æœ‰ç©ºè¡Œ
                          lines.append("| ç­–ç•¥ç»„ | ç±»å‹ |")
                          lines.append("| :--- | :--- |")
                          lines.extend(groups_raw[:15])
                          if len(groups_raw) > 15:
                              lines.append(f"| ... | è¿˜æœ‰ {len(groups_raw)-15} ä¸ª |")
                          lines.append("") # å¿…é¡»æœ‰ç©ºè¡Œ
                          lines.append("</details>")
                          lines.append("")
                  lines.append("---")
                  lines.append("")

              return "\n".join(lines)

          for folder_name, title in CATEGORIES.items():
              readme_content = generate_category_readme(folder_name, title)
              if readme_content:
                  readme_path = os.path.join(folder_name, "README.md")
                  with open(readme_path, "w", encoding="utf-8") as f:
                      f.write(readme_content)
                  print(f"âœ… Generated Report: {readme_path}")
          SCRIPT

      - name: Update Root README (Preserve Manual Content)
        run: |
          python3 << 'SCRIPT'
          import os
          import re

          # å®šä¹‰é”šç‚¹ï¼Œç”¨äºè¯†åˆ«è‡ªåŠ¨æ’å…¥åŒºåŸŸ
          START_MARKER = ""
          END_MARKER = ""

          def get_existing_readme():
              if os.path.exists("README.md"):
                  with open("README.md", "r", encoding="utf-8") as f:
                      return f.read()
              return ""

          def parse_shell_script(script_path):
              if not os.path.exists(script_path): return []
              try:
                  with open(script_path, 'r', encoding='utf-8', errors='ignore') as f:
                      content = f.read()
              except: return []
              
              results = []
              # åŒ¹é…æ›´å¹¿æ³›çš„ URL æ¨¡å¼
              pattern = r'(https?://[^|\s"\']+)\|([^"\n]+?\.ya?ml)'
              matches = re.findall(pattern, content)
              
              for url, output_path in matches:
                  output_path = output_path.strip()
                  # ç®€å•çš„ä½œè€…æå–é€»è¾‘
                  if 'raw.githubusercontent.com' in url:
                      parts = url.split('/')
                      author = parts[4] if len(parts) > 4 else 'unknown'
                  elif 'github.com' in url:
                      parts = url.split('/')
                      author = parts[3] if len(parts) > 3 else 'unknown'
                  else:
                      author = 'External'
                  
                  category = 'Other'
                  if 'General_Config' in output_path: category = 'General'
                  elif 'Smart_Mode' in output_path: category = 'Smart'
                  elif 'Mobile_Modules' in output_path: category = 'Mobile'
                  elif 'Official_Examples' in output_path: category = 'Official'
                  
                  filename = os.path.basename(url)
                  
                  # ç®€å•çš„ä»“åº“é“¾æ¥æ¨æ–­
                  parts = url.split('/')
                  if len(parts) >= 5 and ('github' in url):
                      source_repo = f"https://github.com/{parts[3]}/{parts[4]}"
                  else:
                      source_repo = url

                  results.append({
                      'author': author,
                      'filename': filename,
                      'output': output_path.replace('THEYAMLS/', ''),
                      'category': category,
                      'source_repo': source_repo,
                      'full_url': url
                  })
              return results

          scripts_map = {
              'General_Config': '.github/scripts/download-general.sh',
              'Smart_Mode': '.github/scripts/download-smart.sh', 
              'Mobile_Modules': '.github/scripts/download-mobile.sh',
              'Official_Examples': '.github/scripts/download-official.sh'
          }
          
          all_data = {}
          for cat, script in scripts_map.items():
              all_data[cat] = parse_shell_script(script)

          # --- ç”Ÿæˆè‡ªåŠ¨å†…å®¹å— ---
          new_content_lines = []
          new_content_lines.append(START_MARKER)
          new_content_lines.append("## ğŸ“‚ è‡ªåŠ¨åŒæ­¥é…ç½®åˆ—è¡¨ (Auto-synced Configs)")
          new_content_lines.append("> æœ¬åˆ—è¡¨ç”± GitHub Actions æ¯æ—¥è‡ªåŠ¨ç”Ÿæˆï¼Œæœ€åæ›´æ–°æ—¶é—´: " + os.popen('date -u +"%Y-%m-%d %H:%M UTC"').read().strip())
          new_content_lines.append("")
          
          # å¿«é€Ÿå¯¼èˆªè¡¨
          new_content_lines.append("### ğŸš€ å¿«é€Ÿå¯¼èˆª")
          new_content_lines.append("| åˆ†ç±» | è¯´æ˜ | é…ç½®æ•°é‡ | æ–‡æ¡£å…¥å£ |")
          new_content_lines.append("| :--- | :--- | :--- | :--- |")
          
          cat_info = {
              'General_Config': ('é€šç”¨è¿›é˜¶', 'PC/Mac/æ‰‹æœºé€šç”¨', 'THEYAMLS/General_Config/README.md'),
              'Smart_Mode': ('Smart/è·¯ç”±', 'éœ€é…åˆé­”æ”¹å†…æ ¸/è½¯è·¯ç”±', 'THEYAMLS/Smart_Mode/README.md'),
              'Mobile_Modules': ('Android æ¨¡å—', 'Root ç”¨æˆ·ä¸“ç”¨', 'THEYAMLS/Mobile_Modules/README.md'),
              'Official_Examples': ('å®˜æ–¹ç¤ºä¾‹', 'çº¯å‡€åŸºç¡€é…ç½®', 'THEYAMLS/Official_Examples/README.md')
          }
          
          for key, (name, desc, link) in cat_info.items():
              count = len(all_data.get(key, []))
              if count > 0:
                  new_content_lines.append(f"| **{name}** | {desc} | {count} | [æŸ¥çœ‹è¯¦æƒ…]({link}) |")
          
          new_content_lines.append("")
          new_content_lines.append("---")
          new_content_lines.append("")

          # è¯¦ç»†åˆ—è¡¨
          categories = [
              ('General_Config', 'é€šç”¨è¿›é˜¶é…ç½®'),
              ('Smart_Mode', 'Smart æ¨¡å¼ / è·¯ç”±ä¸“ç”¨'),
              ('Mobile_Modules', 'Android æ¨¡å—ä¸“ç”¨'),
              ('Official_Examples', 'å®˜æ–¹ç¤ºä¾‹')
          ]

          for cat_key, title in categories:
              items = all_data.get(cat_key, [])
              if not items: continue
              
              new_content_lines.append(f"### {title}")
              new_content_lines.append("| ğŸ‘¤ ä½œè€… | ğŸ“„ æ–‡ä»¶ | ğŸ”— æ¥æº |")
              new_content_lines.append("| :--- | :--- | :--- |")
              
              # æŒ‰ä½œè€…èšåˆ
              by_author = {}
              for item in items:
                  auth = item['author']
                  if auth not in by_author: by_author[auth] = []
                  by_author[auth].append(item)
              
              for author, files in sorted(by_author.items()):
                  file_links = "<br>".join([f"[`{f['filename']}`](THEYAMLS/{cat_key}/{f['output']})" for f in files])
                  repo = files[0]['source_repo']
                  repo_link = f"[Source]({repo})"
                  new_content_lines.append(f"| **{author}** | {file_links} | {repo_link} |")
              
              new_content_lines.append("")

          new_content_lines.append(END_MARKER)
          new_block = "\n".join(new_content_lines)

          # --- å°†å†…å®¹æ³¨å…¥ README ---
          current_readme = get_existing_readme()
          
          if START_MARKER in current_readme and END_MARKER in current_readme:
              # æ›¿æ¢ç°æœ‰æ ‡è®°ä¸­çš„å†…å®¹
              pattern = re.compile(f"{re.escape(START_MARKER)}.*?{re.escape(END_MARKER)}", re.DOTALL)
              final_readme = pattern.sub(new_block, current_readme)
              print("âœ… Updated existing section in README.md")
          else:
              # å¦‚æœæ²¡æœ‰æ ‡è®°ï¼Œè¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
              final_readme = current_readme + "\n\n" + new_block
              print("âš ï¸ Markers not found. Appended to end of README.md")

          with open("README.md", "w", encoding="utf-8") as f:
              f.write(final_readme)
          SCRIPT

      - name: Generate OpenClash Configs
        run: |
          python3 << 'SCRIPT'
          import os
          import yaml
          from urllib.parse import quote

          SOURCE_BASE = "THEYAMLS"
          SOURCE_DIRS = [
              "THEYAMLS/Official_Examples",
              "THEYAMLS/General_Config", 
              "THEYAMLS/Smart_Mode",
              "THEYAMLS/Mobile_Modules"
          ]
          OUTPUT_BASE = "Overwrite/THEOPENCLASH"
          GITHUB_REPO = "${{ github.repository }}"
          REPO_RAW_BASE = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main"
          IGNORE_FILES = ["README.md", "LICENSE", "release_body.md"]
          
          yaml.add_multi_constructor("!", lambda loader, suffix, node: None, Loader=yaml.SafeLoader)

          def parse_yaml_file(file_path):
              try:
                  with open(file_path, "r", encoding="utf-8") as f:
                      content = f.read()
                  if "\t" in content:
                      content = content.replace("\t", "  ")
                  data = yaml.safe_load(content)
                  if not isinstance(data, dict):
                      return {"providers": [], "has_providers": False}
                  
                  providers_dict = data.get("proxy-providers", {})
                  if not isinstance(providers_dict, dict) or not providers_dict:
                      return {"providers": [], "has_providers": False}
                  
                  return {"providers": list(providers_dict.keys()), "has_providers": True}
              except:
                  return {"providers": [], "has_providers": False}

          os.makedirs(OUTPUT_BASE, exist_ok=True)
          
          for source_dir in SOURCE_DIRS:
              if not os.path.exists(source_dir):
                  continue
              
              for root, dirs, files in os.walk(source_dir):
                  dirs[:] = [d for d in dirs if not d.startswith(".")]
                  for filename in files:
                      if not filename.endswith((".yaml", ".yml")) or filename in IGNORE_FILES:
                          continue
                      
                      file_path = os.path.join(root, filename)
                      parsed = parse_yaml_file(file_path)
                      
                      if not parsed["has_providers"]:
                          continue
                      
                      rel_path = os.path.relpath(root, SOURCE_BASE)
                      # ä¿®æ­£ OpenClash è¿œç¨‹é“¾æ¥ç”Ÿæˆé€»è¾‘
                      raw_url = f"{REPO_RAW_BASE}/{SOURCE_BASE}/{rel_path.replace(os.sep, '/')}/{quote(filename)}"
                      
                      output_dir = os.path.join(OUTPUT_BASE, rel_path)
                      os.makedirs(output_dir, exist_ok=True)
                      
                      conf_filename = os.path.splitext(filename)[0] + ".conf"
                      output_path = os.path.join(output_dir, conf_filename)
                      
                      lines = [
                          "# --- OpenClash Overwrite Config ---",
                          f"# Source: {filename}",
                          f"# Generated: Auto-generated by GitHub Actions",
                          "",
                          "[General]",
                          "DISABLE_UDP_QUIC = 1",
                          f"DOWNLOAD_FILE = url={raw_url}, path=/etc/openclash/config/{filename}, cron=0 6 * * *, force=false",
                          f"CONFIG_FILE = /etc/openclash/config/{filename}",
                          "SUB_INFO_URL = $EN_KEY1",
                          "",
                          "[Overwrite]",
                          "# EN_KEY: Environment variables for subscription URLs"
                      ]
                      
                      for idx, provider_name in enumerate(parsed["providers"], start=1):
                          lines.append(f'ruby_map_edit "$CONFIG_FILE" "[\'proxy-providers\']" "{provider_name}" "[\'url\']" "$EN_KEY{idx}"')
                      
                      with open(output_path, "w", encoding="utf-8") as f:
                          f.write("\n".join(lines))
                      print(f"âœ… OpenClash: {output_path}")
          SCRIPT

      - name: Generate OpenClash READMEs
        run: |
          python3 << 'SCRIPT'
          import os
          
          OUTPUT_BASE = "Overwrite/THEOPENCLASH"
          if not os.path.exists(OUTPUT_BASE):
              exit(0)
          
          for category in os.listdir(OUTPUT_BASE):
              cat_path = os.path.join(OUTPUT_BASE, category)
              if not os.path.isdir(cat_path):
                  continue
              
              conf_files = [f for f in os.listdir(cat_path) if f.endswith(".conf")]
              if not conf_files:
                  continue
              
              lines = [
                  f"# ğŸ“ {category}",
                  "",
                  "## ğŸ“‹ é…ç½®æ–‡ä»¶åˆ—è¡¨",
                  "",
                  "| æ–‡ä»¶ | è¯´æ˜ |",
                  "| :--- | :--- |"
              ]
              
              for cf in sorted(conf_files):
                  lines.append(f"| `{cf}` | OpenClash è¦†å†™é…ç½® |")
              
              lines.extend([
                  "",
                  "[ğŸ”™ è¿”å› OpenClash æ€»è§ˆ](../README.md)"
              ])
              
              with open(os.path.join(cat_path, "README.md"), "w", encoding="utf-8") as f:
                  f.write("\n".join(lines))

          lines = [
              "# ğŸ“¦ OpenClash è¦†å†™é…ç½®æ–‡ä»¶æ€»è§ˆ",
              "",
              "> ğŸ¤– **è‡ªåŠ¨ç”Ÿæˆ** | åŸºäº THEYAMLS é…ç½®æ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆ",
              "",
              "## ğŸ“‚ åˆ†ç±»ç›®å½•",
              ""
          ]
          
          for category in sorted(os.listdir(OUTPUT_BASE)):
              if os.path.isdir(os.path.join(OUTPUT_BASE, category)):
                  lines.append(f"- ğŸ“ **[{category}](./{category}/README.md)**")
          
          lines.append("")
          lines.append("[ğŸ  è¿”å›é¡¹ç›®ä¸»é¡µ](../../README.md)")
          
          with open(os.path.join(OUTPUT_BASE, "README.md"), "w", encoding="utf-8") as f:
              f.write("\n".join(lines))
          SCRIPT

      - name: Generate INI README
        run: |
          python3 << 'SCRIPT'
          import os
          import re

          def parse_ini_script():
              script_path = ".github/scripts/download-ini.sh"
              if not os.path.exists(script_path):
                  return {}
              
              try:
                  with open(script_path, 'r', encoding='utf-8') as f:
                      content = f.read()
              except: return {}
              
              urls_match = re.search(r'urls=\((.*?)\)', content, re.DOTALL)
              if not urls_match:
                  return {}
              
              urls = re.findall(r'https?://[^\s"\']+', urls_match.group(1))
              categories = {"ACL4Category": [], "Airport": [], "Ordinary": []}
              
              for url in urls:
                  if 'ACL4SSR' in url: cat = "ACL4Category"
                  elif 'jklolixxs' in url or '/customized/' in url or 'Mazeorz/airports' in url: cat = "Airport"
                  else: cat = "Ordinary"
                  
                  if 'raw.githubusercontent.com' in url: author = url.split('/')[4]
                  elif 'github.com' in url: author = url.split('/')[3]
                  elif 'gist' in url: author = url.split('/')[3]
                  else: author = 'External'
                  
                  categories[cat].append({
                      'author': author,
                      'filename': url.split('/')[-1],
                      'url': url
                  })
              return categories

          cat_data = parse_ini_script()
          base_path = "Overwrite/THEINI"
          if not os.path.exists(base_path): exit(0)

          lines = [
              "# ğŸ“‚ INI è¦†å†™é…ç½®é›†åˆ (THEINI)",
              "",
              "> ğŸ”„ è‡ªåŠ¨åŒæ­¥çš„ SubConverter/Clash è¿œç¨‹é…ç½® (INI)",
              "",
              "## åˆ†ç±»ç´¢å¼•",
              ""
          ]

          cat_names = {
              "ACL4Category": ("ğŸ›¡ï¸ ACL4SSR ç³»åˆ—", "åŸºäº ACL4SSR é¡¹ç›®çš„ç»å…¸è§„åˆ™é›†"),
              "Airport": ("âœˆï¸ æœºåœºå®šåˆ¶ç‰ˆ", "å„å¤§æœºåœºæä¾›çš„ä¸“å±å®šåˆ¶é…ç½®"),
              "Ordinary": ("ğŸ“‹ é€šç”¨é…ç½®", "ç¤¾åŒºç»´æŠ¤çš„å…¶ä»–é€šç”¨è§„åˆ™é…ç½®")
          }

          for cat_key, items in cat_data.items():
              if not items: continue
              title, desc = cat_names.get(cat_key, (cat_key, ""))
              lines.append(f"- **{title}**: {desc} ({len(items)} ä¸ª)")
          
          lines.append("")
          
          for cat_key, items in cat_data.items():
              if not items: continue
              title, desc = cat_names.get(cat_key, (cat_key, ""))
              lines.append(f"## {title}")
              lines.append(f"> {desc}")
              lines.append("")
              lines.append("| ğŸ‘¤ ä½œè€… | ğŸ“„ é…ç½®æ–‡ä»¶ | ğŸ”— åŸå§‹é“¾æ¥ |")
              lines.append("| :--- | :--- | :--- |")
              
              for item in items:
                  lines.append(f"| **{item['author']}** | `{item['filename']}` | [Source]({item['url']}) |")
              lines.append("")

          with open(os.path.join(base_path, "README.md"), "w", encoding="utf-8") as f:
              f.write("\n".join(lines))
          SCRIPT

      - name: Commit and Push
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          git add .
          if git diff --staged --quiet; then
            echo "âœ… No changes detected."
            exit 0
          fi
          
          git commit -m "ğŸ¤– Auto: Generate all docs & configs $(date +'%Y-%m-%d')"
          git pull origin ${{ github.ref_name }} --rebase --autostash || true
          git push origin HEAD:${{ github.ref_name }}
